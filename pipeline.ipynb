{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: download selected area's files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import folium\n",
    "from shapely import geometry\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from glob import glob\n",
    "import xml.dom.minidom\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL2A_20200608T161911_N0214_R040_T16PBA_20200608T203054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.11G/1.11G [03:42<00:00, 5.01MB/s]\n",
      "MD5 checksumming: 100%|██████████| 1.11G/1.11G [00:03<00:00, 299MB/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL2A_20200608T161911_N0214_R040_T15PZR_20200608T203054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.19G/1.19G [04:34<00:00, 4.34MB/s]\n",
      "MD5 checksumming: 100%|██████████| 1.19G/1.19G [00:03<00:00, 359MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL1C_20200608T161911_N0209_R040_T16PBA_20200608T195512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 783M/783M [02:58<00:00, 4.39MB/s] \n",
      "MD5 checksumming: 100%|██████████| 783M/783M [00:02<00:00, 325MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL1C_20200608T161911_N0209_R040_T15PZR_20200608T195512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 853M/853M [03:16<00:00, 4.35MB/s] \n",
      "MD5 checksumming: 100%|██████████| 853M/853M [00:02<00:00, 346MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL2A_20200526T160911_N0214_R140_T16PBA_20200526T203535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 530M/530M [02:01<00:00, 4.36MB/s] \n",
      "MD5 checksumming: 100%|██████████| 530M/530M [00:01<00:00, 352MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL2A_20200524T161829_N0214_R040_T15PZR_20200524T200337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.17G/1.17G [04:29<00:00, 4.33MB/s]\n",
      "MD5 checksumming: 100%|██████████| 1.17G/1.17G [00:03<00:00, 339MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL2A_20200524T161829_N0214_R040_T16PBA_20200524T200337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.06G/1.06G [04:03<00:00, 4.33MB/s]\n",
      "MD5 checksumming: 100%|██████████| 1.06G/1.06G [00:02<00:00, 360MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL1C_20200524T161829_N0209_R040_T16PBA_20200524T193829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 732M/732M [02:52<00:00, 4.25MB/s] \n",
      "MD5 checksumming: 100%|██████████| 732M/732M [00:02<00:00, 356MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL1C_20200524T161829_N0209_R040_T15PZR_20200524T193829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 833M/833M [03:12<00:00, 4.34MB/s] \n",
      "MD5 checksumming: 100%|██████████| 833M/833M [00:02<00:00, 354MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL1C_20200521T160829_N0209_R140_T16PBA_20200521T193318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 347M/347M [01:21<00:00, 4.25MB/s] \n",
      "MD5 checksumming: 100%|██████████| 347M/347M [00:01<00:00, 335MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL1C_20200516T160911_N0209_R140_T16PBA_20200516T212856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 86.9M/86.9M [00:20<00:00, 4.21MB/s]\n",
      "MD5 checksumming: 100%|██████████| 86.9M/86.9M [00:00<00:00, 354MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL2A_20200501T160819_N0214_R140_T16PBA_20200501T201410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 512M/512M [01:58<00:00, 4.32MB/s] \n",
      "MD5 checksumming: 100%|██████████| 512M/512M [00:01<00:00, 353MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2B_MSIL1C_20200501T160819_N0209_R140_T16PBA_20200501T193300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 325M/325M [01:14<00:00, 4.37MB/s] \n",
      "MD5 checksumming: 100%|██████████| 325M/325M [00:00<00:00, 355MB/s] \n"
     ]
    }
   ],
   "source": [
    "api =SentinelAPI('Molan_Zhang', 'Lan19980520.','https://scihub.copernicus.eu/apihub/')\n",
    "\n",
    "footprint =geojson_to_wkt(read_geojson('./Downloads/deslizamientos.geojson'))\n",
    "\n",
    "products =api.query(footprint,date=('20200501','20200610'), platformname='Sentinel-2', cloudcoverpercentage=(0,30))\n",
    "\n",
    "product_name = []\n",
    "for product in products:\n",
    "    product_info = api.get_product_odata(product)\n",
    "    print(product_info['title'])\n",
    "    product_name.append(product_info['title'])\n",
    "    api.download(product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: transfer zip file as GeoTIFF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import GeoTIFF package\n",
    "import gdal\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "from osgeo import ogr\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Input file size is 10980, 10980\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "osgeo_home_bin = \"C:\\\\OSGeo4W64\\\\bin\"\n",
    "os.environ['PATH'] = ''.join([osgeo_home_bin,\";\",os.environ['PATH']])\n",
    "for file_name in product_name: \n",
    "    quary = 'gdalinfo '+file_name+'.zip'\n",
    "    info = os.popen(quary)\n",
    "    d = info.read()\n",
    "    d = d.split('SUBDATASET_1_NAME=')\n",
    "    d = d[1].split('\\n')\n",
    "    q = 'gdal_translate ' + d[0] + ' '+file_name+'.tif'\n",
    "    info = os.popen(q)\n",
    "    d = info.read()\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: create a model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the GeoTIFF file\n",
    "def read_img(dataset): \n",
    "    im_width = dataset.RasterXSize    \n",
    "    im_height = dataset.RasterYSize\n",
    "    im_geotrans = dataset.GetGeoTransform() #affine matrix \n",
    "    im_proj = dataset.GetProjection() #Map projection information \n",
    "    im_bands = dataset.RasterCount\n",
    "    im_data = dataset.ReadAsArray(0,0,im_width,im_height) \n",
    "    del dataset \n",
    "    return im_proj,im_geotrans,im_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndvi(data):  \n",
    "    band8 = data[3]\n",
    "    band4 = data[0]\n",
    "    molecule = band8 - band4\n",
    "    denominator = band8 + band4\n",
    "    band = molecule / denominator\n",
    "    band[band > 1] = 9999  \n",
    "    return band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndwi(data):  \n",
    "    band8 = data[3]\n",
    "    band3 = data[1]\n",
    "    molecule = band8 - band3\n",
    "    denominator = band8 + band3\n",
    "    band = molecule / denominator\n",
    "    band[band > 1] = 9999  \n",
    "    return band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model based on sample tiff file\n",
    "def create_model():\n",
    "    sample_path = 'E:/molan_research/flood/geo_tiff/S2A_MSIL1C_20200608T161911_N0209_R040_T16PBA_20200608T195512_MDClass.tif'\n",
    "    sample_db = gdal.Open(sample_path)\n",
    "    class_count = 6\n",
    "    sp_proj,sp_geotrans,sp_data = read_img(sample_db)\n",
    "    X=[[] for j in range(class_count)]\n",
    "    for y in range(0, 10980):\n",
    "        for x in range(0, 10980):\n",
    "            i=0\n",
    "            while i < class_count:\n",
    "                if int(sp_data[0][y][x])==i:\n",
    "                    X[i].append([y,x])\n",
    "                i=i+1\n",
    "    sample_im_path = 'E:/molan_research/flood/geo_tiff_pic/S2A_MSIL1C_20200608T161911_N0209_R040_T16PBA_20200608T195512.tif'\n",
    "    sample_im_db = gdal.Open(sample_im_path)     \n",
    "    sp_im_proj,sp_im_geotrans,sp_im_data = read_img(sample_im_db)\n",
    "    ndvi = get_ndvi(sp_im_data)\n",
    "    ndwi = get_ndwi(sp_im_data)\n",
    "    sp_img_data = np.zeros((6,10980,10980))\n",
    "    model_file = open('E:/molan_research/flood/MD_model.txt','w')\n",
    "    for i in range(4) :\n",
    "        temp = np.max(sp_im_data[i])\n",
    "        sp_img_data[i,:,:] = sp_im_data[i]/temp\n",
    "    sp_img_data[4,:,:] = ndvi\n",
    "    sp_img_data[5,:,:] = ndwi\n",
    "    input_data = np.sum(sp_img_data,0)\n",
    "    model = []\n",
    "    avg=0\n",
    "    for i in range(class_count):\n",
    "        for j in range(len(X[i])):\n",
    "            y=X[i][j][0]\n",
    "            x=X[i][j][1]\n",
    "            avg = avg + input_data[y][x]\n",
    "        avg_sum=avg/len(X[i])\n",
    "        model.append(avg_sum)\n",
    "        model_file.write(str(avg_sum)+'\\n')\n",
    "        avg=0.0\n",
    "    model_file.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    model_file = open(path,'r')\n",
    "    model = []\n",
    "    for line in f:\n",
    "        model.append(float(line.strip('\\n').split(',')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Do detaction for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect \n",
    "\n",
    "def cal_box(model,data):  # 计算矩阵求最小值\n",
    "    height,width = data.shape\n",
    "    ans = np.zeros((height,width)) - 1\n",
    "    ans_cloud_free = np.zeros((height,width)) - 1\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if np.isnan(data[i][j]):\n",
    "                continue\n",
    "            ans_pic = []\n",
    "            for k in range(len(model)) : \n",
    "                flag = model[k]\n",
    "                differ = abs(data[i][j]-flag)\n",
    "                ans_pic.append(differ)\n",
    "            if ans_pic.index(min(ans_pic)) == 1:\n",
    "                ans_cloud_free[i][j] = -1\n",
    "            else:\n",
    "                ans_cloud_free[i][j] = ans_pic.index(min(ans_pic))\n",
    "            ans[i][j] = ans_pic.index(min(ans_pic))\n",
    "    return ans,ans_cloud_free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create vector GeoTiff file for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_label(im_data):\n",
    "    water=[255,0,0]\n",
    "    low_vegetation=[0,255,0]\n",
    "    build_up=[0,0,255]\n",
    "    bare_land = [128,64,0]\n",
    "    no_data = [255,255,255]\n",
    "    cloud = [128,128,128]\n",
    "    forest = [34,139,34]\n",
    "    height,width = im_data.shape\n",
    "    label_pic = np.zeros((3,height,width))\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if im_data[i][j] == -1 :\n",
    "                label_pic[:,i,j] = no_data\n",
    "            elif im_data[i][j] == 0 :\n",
    "                label_pic[:,i,j] = water\n",
    "            elif im_data[i][j] == 1 :\n",
    "                label_pic[:,i,j] = cloud\n",
    "            elif im_data[i][j] == 2 :\n",
    "                label_pic[:,i,j] = build_up\n",
    "            elif im_data[i][j] == 3 :\n",
    "                label_pic[:,i,j] = bare_land\n",
    "            elif im_data[i][j] == 4 :\n",
    "                label_pic[:,i,j] = forest\n",
    "            elif im_data[i][j] == 5 :\n",
    "                label_pic[:,i,j] = low_vegetation\n",
    "    return label_pic\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img(filename,im_proj,im_geotrans,im_data):\n",
    "        #type of data in gdal\n",
    "        #gdal.GDT_Byte, \n",
    "        #gdal .GDT_UInt16, gdal.GDT_Int16, gdal.GDT_UInt32, gdal.GDT_Int32,\n",
    "        #gdal.GDT_Float32, gdal.GDT_Float64\n",
    " \n",
    "        if 'int8' in im_data.dtype.name:\n",
    "            datatype = gdal.GDT_Byte\n",
    "        elif 'int16' in im_data.dtype.name:\n",
    "            datatype = gdal.GDT_UInt16\n",
    "        else:\n",
    "            datatype = gdal.GDT_Float32\n",
    " \n",
    "        if len(im_data.shape) == 3:\n",
    "            im_bands, im_height, im_width = im_data.shape\n",
    "        else:\n",
    "            im_bands, (im_width, im_height) = 1,im_data.shape \n",
    " \n",
    "        driver = gdal.GetDriverByName(\"GTiff\")            \n",
    "        dataset = driver.Create(filename, im_width, im_height, im_bands, datatype)\n",
    "        dataset.SetGeoTransform(im_geotrans)              \n",
    "        dataset.SetProjection(im_proj)                   \n",
    "        if im_bands == 1:\n",
    "            dataset.GetRasterBand(1).WriteArray(im_data)  \n",
    "        else:\n",
    "            for i in range(im_bands):\n",
    "                dataset.GetRasterBand(i+1).WriteArray(im_data[i])\n",
    "                print(im_data[i].shape)\n",
    "        del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "for file_name in product_name:\n",
    "    # calculate NDVI & MDWI band for each file\n",
    "    new_data = np.zeros((6,10980,10980))\n",
    "    dataset=gdal.Open(file_name+'.tif')\n",
    "    im_proj,im_geotrans,im_data = read_img(dataset)\n",
    "    ndvi = get_ndvi(im_data)\n",
    "    ndwi = get_ndwi(im_data)\n",
    "    for i in range(4) :\n",
    "        temp = np.max(im_data[i])\n",
    "        new_data[i,:,:] = im_data[i]/temp\n",
    "    new_data[4,:,:] = ndvi\n",
    "    new_data[5,:,:] = ndwi\n",
    "    input_pic = np.sum(new_data,0)\n",
    "    ans,ans_cloud_free = cal_box(model,input_pic)\n",
    "    save_path = 'E:/molan_research/flood/geo_tiff_test/'\n",
    "    write_img('E:/molan_research/flood/geo_tiff_test/'+file_name+'_class.tif',im_proj,im_geotrans,ans)\n",
    "    write_img('E:/molan_research/flood/geo_tiff_test/'+file_name+'_cloud_free.tif',im_proj,im_geotrans,ans_cloud_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
